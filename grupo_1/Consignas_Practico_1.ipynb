{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Consignas - Practico 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "## Práctico Análisis y Visualización\n",
        "\n",
        "El siguiente trabajo esta pensado para ser entregado en formato de tipo informe en un notebook Python hecho en Jupyter Lab o Google Colab. Debera apuntar a un público técnico con conocimientos generales del tema. \n",
        "\n",
        "La presentación de los resultados debe ser clara, apoyar las conclusiones extraidas y ser lo mas sintetico posible. No necesariamente todo lo que prueben debe estar reflejado en el informe. Ciertamente valoramos el esfuerzo de explorar alternativas de análisis y visualización, pero parte del trabajo es elegir también las mas adecuadas. \n",
        "\n",
        "----\n",
        "\n",
        "## Consignas\n",
        "\n",
        "### 1. Armado del dataset\n",
        "\n",
        "Inicialmente nuestro conjunto de datos se encuentra distribuido en varios archivos. Es necesario juntar todo en un mismo set de datos para facilitar la manipulacion. \n",
        "\n",
        "- Describir las caracteristicas generales de los datasets presentes en los archivos de entrada: Numero de registros, diferencias entre los mismos. \n",
        "- Definir conveniencia de usar todos los datos juntos en un mismo dataset o separarlos. \n",
        "\n",
        "### 2. Exploración\n",
        "\n",
        "- De que consta nuestro dataset? que tipo de datos tenemos?\n",
        "- Nuestra variable a predecir, esta balanceada dentro del dataset etiquetado?\n",
        "- Que tipo de curacion creen que seria necesaria realizar? Existen datos nulos?\n",
        "- En base a lo que podemos entender conceptualmente sobre nuestras variables, existe alguna que a priori pueda tener una mayor influencia sobre nuestro objetivo a predecir? por qué?\n",
        "- Existe correlacion entre las variables del dataset? Cual metodo de cálculo de correlacion conviene usar para este tipo de variables?\n",
        "\n",
        "### 3. Visualización\n",
        "\n",
        "- Como se distribuyen las variables? Cuales siguen una distribucion normal y cuales no?\n",
        "- Explorar las diferencias entre las distribuciones de las distintas variables: \n",
        "  - según el paciente\n",
        "  - según la etiqueta a predecir\n",
        "  - ambas (usar hue)\n",
        "- Hay outliers presentes en nuestras distribuciones? habria que sacarlos?\n",
        "\n",
        "### **Sobre los datos no etiquetados**\n",
        "\n",
        "Si bien todavia no vamos a predecir una etiqueta, nos interesa entender lo mas posible sobre estos datos para poder entender las predicciones de los modelos.\n",
        "\n",
        "- Visualizar las distribuciones de las distintas metricas. Se comportan parecido a los etiquetados si eliminaramos las etiquetas? y si las consideramos?\n",
        "\n",
        "### 4. Conclusiones\n",
        "\n",
        "Sobre los datos etiquetados: \n",
        "- En base al análisis, se pudo encontrar cual(es) son las métricas que mejor diferencian un estado de otro?\n",
        "\n",
        "Sobre los no etiquetados:\n",
        "- Conviene analizarlos junto con los que si estan etiquetados? \n",
        "\n",
        "### 5. Opcional: Analizar las señales originales y obtener un nuevo cuantificador.\n",
        "\n",
        "- Para las señales de EEG de un paciente , acceder a cada uno de los datos de EEG\n",
        "\n",
        "Para cada archivo: \n",
        "\n",
        "- Preprocesar las señales (aplicar filtro de pasa banda ) pertenecientes a los 16 canales \n",
        "- Analizar la entropía espectral de cada una de las señales y calcular el valor medio sobre todos los canales.\n",
        "- Almacenar los datos en un Data Frame  \n",
        "\n",
        "*la entropía espectral se calcula usando el paquete  [antropy](https://github.com/raphaelvallat/antropy) (se instala con $ pip instal antropy). \n",
        "\n",
        "El comando es antropy.spectral_entropy(señal, sf=400, method='welch', normalize=True))   (señal es la señal de EEG , los otros parametros quedan fijos)"
      ],
      "metadata": {
        "id": "PqwpS9LFpLtn"
      }
    }
  ]
}